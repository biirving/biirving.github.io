<!DOCTYPE html>
<html>
  <head>
    <title>Ben Irving</title>
    <style>
      title {
        font-family: Arial, sans-serif
      }
      p {
        font-family: Arial, sans-serif;
      }
      h1 {
        font-family:Arial, Helvetica, sans-serif
      }
      h2 {
        font-family:Arial, Helvetica, sans-serif
      }
      ul {
        font-family: Arial, Helvetica, sans-serif;
      }
    </style>
  </head>
  <body>
    
    <h1>Ben Irving</h1>
    <p>My name is Ben, and I am currently a computer science student at Northeastern University interested in generative models.</p>
    <h2>Projects</h2>
    <p>Here are some projects I have done, and some I am still working on:</p>
    <ul>
      <h2>Equivariant Proximal Policy Optimization With Behavioral Cloning</h2>
      <p>
        Equivariance has been shown to increase sample efficiency in many different reinforcement learning algorithms. 
        These models are particularly relevant for classic control and robotic manipulation learning problems,
        where state spaces can be thought of as symmetric under rotation. This paper builds on previous work,
        examining the model architecture for equivariant actor-critic methods, and how symmetry can burnish the 
        Proximal Policy Optimization (PPO) algorithm. The code is avilable at <a href="https://github.com/biirving/aur_ppo" target="_blank">AUR_PPO GitHub Repository</a>
      </p>
      <img src="robot_arm" alt="A snippet of the environment">
    </ul>
    <ul>
      <li>Multimodal encoding antecedant information.</li>
    </ul>
  </body>

  <!-- Add this link to your "Essays" page -->
    <a href="essays.html">Essays and Stories</a>
</html>
